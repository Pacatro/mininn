# üèÅ TODOs

## IMPORTANT

- [x] New costs functions
- [x] Batch in train algorithm
- [x] Add optimizers
- [x] Add Dropout layer
- [x] FIX INPUTS/OUTPUTS DIMENSIONS
- [x] Create custom Cost
- [x] Create custom Activation functions
- [ ] FIX PROBLEMS WITH ACTIVATION REGISTER (SHOULD USE TYPEID INSTEAD OF A CONSTRUCTOR????)
- [ ] Add BatchNorm layer
- [ ] Add Conv layer
- [ ] Add Pooling layer
- [ ] Add Deconv layer
- [ ] Add Embedding layer
- [ ] Add Recurrent layer

## NOT IMPORTANT

- [ ] Fix Adam optimizer
- [ ] New docs
- [ ] Allow users to set type of the numbers used in the neural network (f32 or f64)
