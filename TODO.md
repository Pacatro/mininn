# üèÅ TODOs

## IMPORTANT

<!--- v0.1.5 LAYERS --->
[Layers implementations](https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/deep_learning/)

- [x] Implement Xavier initialization
- [ ] Add BatchNorm layer
- [ ] Add Conv layer
- [ ] Add Pooling layer
- [ ] Add Deconv layer
- [ ] Add Embedding layer
- [ ] Add Recurrent layer
- [ ] Fix Adam optimizer
- [ ] [Fix optimizers](https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be)

<!--- v0.2.0 OPTIMIZATIONS --->
- [ ] Improve backpropagation ([resilient propagation](https://medium.com/@Ahmad_AM0/resilient-propagation-e76b569beea2))
- [ ] [Multithreading](https://www.heatonresearch.com/encog/mprop/compare.html)
- [ ] Try to use GPU (WGPU, torch, etc)

## NOT IMPORTANT

- [ ] See erased-serde
- [ ] Refactoring train algorithm
- [ ] Web for docs and examples
- [ ] Allow users to set type of the numbers used in the neural network (f32 or f32)
