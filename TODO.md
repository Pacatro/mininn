# üèÅ TODOs

## IMPORTANT

<!--- v0.1.5 LAYERS --->
[Layers implementations](https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/deep_learning/)

- [ ] ABSTRACT NN DATA FOR DIFFERENTS DIMENSIONS (use a trait to define the data (NNData))
- [x] Implement Xavier initialization
- [x] Add Reshape layer
- [x] Add Conv2D layer
- [ ] Add Pooling2D layer
- [ ] Add Deconv2D layer
- [ ] Add BatchNorm layer
- [ ] Add Generic trait for Netowrk data (Image, ....)
- [ ] [Fix optimizers](https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be)

<!--- v0.2.0 OPTIMIZATIONS --->
- [ ] Improve backpropagation ([resilient propagation](https://medium.com/@Ahmad_AM0/resilient-propagation-e76b569beea2))
- [ ] [Multithreading](https://www.heatonresearch.com/encog/mprop/compare.html)
- [ ] Try to use GPU (WGPU, torch, etc)

## FUTURE UPDATES

- [ ] Add Embedding layer
- [ ] Add Recurrent layer
- [ ] Fix Adam optimizer
- [ ] Add Conv3D layer
- [ ] Add Pooling3D layer
- [ ] Add Deconv3D layer

## NOT IMPORTANT

- [ ] See erased-serde
- [ ] Refactoring train algorithm
- [ ] Web for docs and examples
- [ ] Allow users to set type of the numbers used in the neural network (f32 or f32)
